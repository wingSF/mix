# 小文件合并项目总结
* 背景
    * 在大数据的dfs中，存在着很多大小特别小的文件，这些文件会影响hadoop的计算性能，考虑写一个分布式的任务调度程序，将这些小文件合并成一个大文件，期间踩坑无数，有的已经蹚平，有的仍需研究，终于有时间，做一记录，以总结最近的所见所得所思所想。
* 涉及技术点
    * 线程池
        * 线程池选型
            * ```Executors``` 提供的 ```newFixedThreadPool```，```newCachedThreadPool```有诸多不确定点，建议结合自己的实际情况使用
                * newFixedThreadPool
                    * 队列使用了```new LinkedBlockingQueue<Runnable>()```的申明方式，就决定了该队列的最大值为```Integer.MAX_VALUE```.
                    > 这里只说有问题的场景，当线程的处理能力达到瓶颈时，队列会一直堆积元素到Integer的最大值，可能会发生OOM  
                    参考 arithmetic工程下FixedThreadPoolDemo.java文件
                * newCachedThreadPool
                    * 核心线程数为0，最大线程数使用```Integer.MAX_VALUE```的申明方式，会导致线程在使用的时候才会创建，且无上限，而且当线程池休息的时候，只要超过timeout会kill掉所有线程
        * 线程池队列选型
            * 可参见 arithmetic工程下的 queueDemo包
            * 在决定自己继承```ThreadPoolExecutor```实现线程池的时候发现，线程池的队列申明是```BlockingQueue```，疑问有二
                * 为什么是阻塞队列
                    * 这个问题，一拍脑袋，非阻塞一定比阻塞效率要高，所以百思不得其解。最终反问了自己一下，如果队列中元素为空了，这个时候线程应该怎么做，会发现，非阻塞队列的时候，如果一直pull元素，cpu会高居不下...
                * 为什么要把Deque排除
                    * 不得解不得解//todo
                    * Deque有俩头操作的特性，可用于工作窃取，这样当前线程从头向尾工作，别的线程可以从尾巴部位，偷取几个任务，互不干涉。
        * 线程池worker的理解
            * execute
                * 方法的参数是```Runnable```,该接口中有一个抽象方法是```run```方法，Thread类实现了该接口
                * 当一个Runnable的子类对象被提交之后，会将该对象以offer的方式添加到workQueue中(查看execute的源码可得)
                * ```workerCountOf(c) < corePoolSize```如果线程数小于核心线程数，则创建线程执行该任务```addWorker(command, true)```
                * 注意```#addWorker```的第二个参数，为true时，是核心线程数，为false时，是最大线程数
                * 调用```#addWorker```有三个场景，上面提到一个参数为true的场景，另外俩个分别是
                    * 当任务添加队列成功的时候，会再次检测是否有可用的线程，因为线程可能会因为idle时间过程被clean掉|线程池已经shut down，此时会增加worker，且参数为false
                    > 该逻辑很少被人提及，还是要自己看啊.....这个地方有注释，可以参考
                    * 当任务添加队列失败的时候，会创建worker，参数为false，如果创建失败，则调用拒绝策略
                * 说完了调用```#addWorker```，说说这个方法内部，一大坨逻辑啊//todo
            * submit
                * 方法的参数也是```Runnable```,该方法位于```AbstractExecutorService```中，重载的方法有三个，参数分别是```(Runnable)| (Runnable，Result)| (Callable)```
                * 之后会通过该抽象类的```#newTaskFor```方法，把请求封装成```RunnableFuture```对象，然后提交给workQueue
                    * 此处埋下一个bug
                * 当被线程池poll出来之后，先执行```FutureTask```的run方法，内部会调用```Runnable|Callable```的run或者call方法
            * 认知理解
                * 以前一直将线程和任务这俩个东西混为一谈，但实际上，线程是一个操作系统分配的用来执行任务的资源，而任务才是真正的业务逻辑，所以使用Thread类，将业务写在run方法里面，是不合理的。
                * 所以出现了线程池的概念，线程池用来维护工作的资源，不关心你实际执行任务的内容。任务自己去实现```Runnable```接口，然后将任务提交到线程池。这样做到各司其职，边界清晰。
            * 一句话总结submit与execute的区别
                * ```FutureTask#run```源码中，除c.call()的逻辑
            * 坑
                * 优先级队列
                    * 无界队列导致最大线程参数无效，这个取决于线程池的默认实现，因为队列永远无法填满，所以不会创建比核心线程数更多的线程
                    * ```ThreadPoolExecutor#getTask```方法中，workQueue的pool或者take方法的调用，实际调用优先级队列的实现
                        * ```PriorityBlockingQueue```类中关于元素排序的核心方法```siftUpComparable|siftDownComparable```
                        * 上述俩个方法的第一步操作```Comparable<? super T> key = (Comparable<? super T>)x;```就是要将需要排序的对象强制类型转化
                        * 所以使用PriorityBlockingQueue,使用submit()提交任务时，一定要重写线程池的newTaskFor()方法，原有的```FutureTask```对象会报类型转化异常，也就是上面提到的bug
                    * 另注:只要存在高优先级任务，低优先级任务就不会被执行
        * 线程池task cancel/interrupted理解
            * cancel
                * 该方法是```Future```顶层接口定义的方法，最标准的解释还需参考java doc，这里只说关键的几个点。
                * 理论
                    * 如果该任务，还没有执行，则不会再执行，返回cancel成功
                    * 如果该任务已经执行完，则返回cancel失败
                    * 如果该任务在执行中，则根据参数来决定，是否interrupt执行中的线程
                * 实现
                    * ```FutureTask```
                    * 内部有一个volatile的标志位用来记录任务的执行状态(一共7中状态，4种转换过程，可以在javadoc中找到)
                    * 状态转换的过程可以参见```FutureTask#run```,使用了```UNSAFE```类的CAS操作完成
                    * cancel任务的效果实现，结合了本身的run得以实现，详细过程如下
                        * submit时，将Task封装为```FutureTask```，提交到线程池的workqueue中
                        * 当被cancel的时候，修改```FutureTask```对象的status属性
                        * 当被线程池调用时，先执行```FutureTask```的run方法，当检测到status不是new或者将runner字段变更为当前线程失败的时候，就直接return
            * interrupt(线程中断)
                * 问题:总是会看到一些方法描述说，响应中断，不响应中断，这个如何理解呢
                * 解答
                    * 当a线程submit一个任务到线程池时，此时a线程可以拿到任务的FutureTask对象，对任务进行追踪。线程池内部的线程p1会执行该任务。
                    * 当a线程发现任务执行超时，调用了cancel方法且参数为true之后，会调用p1线程的interrupt方法，p1线程会修改自己的线程状态为中断
                    * 但是p1线程是顺序执行任务的代码逻辑，其中有一些方法是会响应中断的，但有一些不会。能响应中断的方法，会在调用时，判断标志位，同时抛出InterruptException，而不响应的方法则会自己执行，不管中断标志位。
        * 实践经验部分
            * 批量提交任务后的超时控制方式
                * 在大部分使用场景，任务的提交者的速度要远远大于任务的处理者。
                * 当需要对任务进行跟踪时，只有提交任务的线程调用线程池的submit方法才能拿到```FutureTask```对象，来跟踪任务执行
                * 任务的提交者一般是提交一批任务，这个时候得到的是很多```FutureTask```对象
                * 对于每个```FutureTask```对象，做超时控制如何实现？
                    * 先思考再来寻求解，才会觉得有意义。。。
                        * 可以取最后一个任务提交的时间为起始时间
                        * 然后等待约定的超时时间
                        * 然后再去判断```FutureTask#isDone```
                        * 此时任务正常都应该完成，可能最后提交的某几个任务会因为执行时间太短导致无法完成，需要通过持久化的一致性进行重做(状态机机制)
    * springboot中的config配置/bean配置/propertySource
        * config配置
            * 项目配置可以通过一个配置类来实现，借助```@ConfigurationProperties```，借助prefix实现
            * 当多个互不相干的业务配置出现的时候，可以通过内部类的方式，进行配置再次划分，此处需要在当前类中申明内部类的对象
            > 可参考工程 spring-boot-study-demo/spring-boot-configuration项目中```ProjectProperties```的配置方式
        * bean配置
            * 使用@Bean注解，可以在被```@Component```注解标志的类内，初始化Bean
        * propertySource
            * 在使用spring Schedul时候，为了达到调度频次可配置化，使用了该注解。原因是使用```@Scheduled```的时候，参数只识别字符串
            > 可参考工程 spring-boot-study-demo/spring-boot-configuration项目中```Job```的配置方式
    * spring Schedul调度
        * fixRate/fixDelay
        * 以及fixDelay未生效后，使用atomicBoolean做的补救措施
        * 如何调用代码的，详细过程
    * httpclient
        * 返回stream的处理与连接的关系，以及try-with-stream的处理方式
    * 分布式任务的领取一致性处理方式
        * mysql update(+where条件+任务状态机)，一定只有一个线程能update状态成功
        * 分布式锁
    * 文件超过
        * guava Files
            * asByteSink
                * 文件路径错误导致流未消费问题，进而引发链接耗尽
                > AutoAbortInputStream objectContent = objectResult.getObject().getObjectContent();  
                Files.asByteSink(originalFile, FileWriteMode.APPEND).writeFrom(objectContent);
                * 上方代码中，由于originalFile的路径申明报错，导致objectContent这个stream对象没有被合理close，导致出现引发httpclient链接耗尽问题，这个会在本页的httpclient部分详述
                * 最终改进代码
                ```java
                    try (AutoAbortInputStream objectContent = objectResult.getObject().getObjectContent()) {
                      Files.asByteSink(originalFile, FileWriteMode.APPEND).writeFrom(objectContent);
                    } catch (Exception e) {
                    }
                ```
            * readLines
                * 将整个文件读入内存进行操作，引发的OOM问题
                * 由于本次是文件操作，当出现超大文件的时候，发现jvm，fgc频率超高，最终系统宕机，分析堆栈中最大的对象是[C
                * 原因，文件读取的时候，使用了该方法一次性将整个文件加载到内存中，出现了很多String对象，而String对象是使用[C存储的(查看String源码，成员变量的申明)
                * 解决办法，使用```BufferedReader ```乖乖的一行一行的读取
    * JVM GC监控，得到的结论
        * 先上jstat -gcutil pid 1000(时间间隔，毫秒)的输出
        >  S0     S1     E      O      M     CCS    YGC     YGCT    FGC    FGCT     GCT   
            0.00  98.00  59.54  70.91  96.55  94.03    695   45.151     3    0.289   45.439  
            0.00  98.00  59.54  70.91  96.55  94.03    695   45.151     3    0.289   45.439  
            0.00  98.00  59.54  70.91  96.55  94.03    695   45.151     3    0.289   45.439
        * 上方是服务稳定的情况下，截取的输出。简单介绍S0，S1是俩个使用复制算法的回收区域，每次只有一个区域有数据，每次回收都会把一个区域的所有数据压缩，存储到另外一个区域
        * E是新生代，声明周期比S0,S1略长，当E区无法新开辟对象的时候，触发回收，部分对象被清理，部分晋升到O区
        * 当E区GC后空间不足以存放新对象的时候，会在O区之间创建对象
        * 当O区也无法容纳新对象的时候，会触发FGC，FGC之后仍无法开辟空间容纳新对象后，整个系统也就崩掉了，此时FGC|FGCT会一直增加
    * log4j2的日志配置
    