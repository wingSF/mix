# java内存模型
## 线程间如何通信/线程间如何同步
* 命令式编程中，通信机制有'共享内存'和'消息传递'
    * 共享内存
        * 通过读写内存，完成隐式的消息传递
    * 消息传递
        * 通过线程互相发送消息
* 同步
    * 程序中用于控制不同线程间操作发生相对顺序的机制
        > 在共享内存的并发模型中，同步操作需要代码显式的指出，哪段代码需要在线程之间互斥执行  
    在消息传递的并发模型中，只有代码执行完了，才发送消息，所以同步是隐式进行的  
* java的并发采用了共享内存的方式，所以线程间通信是完全透明的。

## java内存模型的结构
* 实例域/数组元素存储在堆区，堆区线程共享，非线程共享的数据不会存在内存访问可见性的问题
* java内存模型，由JMM定义。JMM决定了一个线程对共享变量的修改，什么时候对其它线程可见
* JMM定义了线程与主内存之间的关系，线程之间共享的变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中缓存了读写的共享变量的副本
> JMM只是一个抽象概念，本身并不存在，涵盖了缓存/写缓冲区/寄存器/以及其它硬件和编译器优化

## 从源代码到指令序列的重排序
* 在程序执行是，为了提高性能，会对指令进行重排序
* 重排序
    * 编译器的重排序
    * 处理器的指令并行
        * 通过流水线等技术实现多条指令同时并行执行的并行技术
    * 处理器的重排序
        * 由于读写的时候可能发生在缓冲区，可能发生在主内存，所以看起来是在乱序执行
* java如何控制重排序
    * java编译器会禁止特定类型编译器重排序
    * 通过编译器在指令中插入内存屏障控制处理器的重排序
* 写缓冲区
    * 现代处理器，将临时保存的数据写入写缓冲区。这样可以保证指令不切换到主内存进行等待而继续执行
    * 通过批量刷新的方式，减少了内存对总线的占用
    * 坏处:由于写缓冲区只对当前cpu可见，会导致处理器对读写指令的执行顺序与预期不同
* 现代处理器都会允许写-读指令重排序，但是存在数据依赖的情况不允许重排序
* 为了控制重排序，java通过插入内存屏障，来解决问题
* 内存屏障
    * loadload:load1;loadload;load2-->load1的指令优先于load2及后续指令的执行
    * storestore:store1:storestore:store2-->store1的指令刷新到内存，store2才能执行
    * loadstore:load1:loadstore:store2-->load1优先与store2的执行
    * storeload:store1:storeload:load2-->store1操作完成后，才能load2
* happens-before原则
    * 一个线程中的每个操作，都先行发生于当前线程的后续其它操作
    * 对一个锁的解锁操作，先行发生与随后对这个锁的加锁//todo不理解啊
    * 对一个volatile的写，先行发生与后续对这个volatile的读//todo不理解啊
    * 如果a 先行发生与b ，b 先行发生与 c ，则 a 先行发生与 c
