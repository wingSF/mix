# java内存模型
## 线程间如何通信/线程间如何同步
* 命令式编程中，通信机制有'共享内存'和'消息传递'
    * 共享内存
        * 通过读写内存，完成隐式的消息传递
    * 消息传递
        * 通过线程互相发送消息
* 同步
    * 程序中用于控制不同线程间操作发生相对顺序的机制
        > 在共享内存的并发模型中，同步操作需要代码显式的指出，哪段代码需要在线程之间互斥执行  
    在消息传递的并发模型中，只有代码执行完了，才发送消息，所以同步是隐式进行的  
* java的并发采用了共享内存的方式，所以线程间通信是完全透明的。

## java内存模型的结构
* 实例域/数组元素存储在堆区，堆区线程共享，非线程共享的数据不会存在内存访问可见性的问题
* java内存模型，由JMM定义。JMM决定了一个线程对共享变量的修改，什么时候对其它线程可见
* JMM定义了线程与主内存之间的关系，线程之间共享的变量存储在主内存中，每个线程都有一个私有的本地内存，本地内存中缓存了读写的共享变量的副本
> JMM只是一个抽象概念，本身并不存在，涵盖了缓存/写缓冲区/寄存器/以及其它硬件和编译器优化

## 从源代码到指令序列的重排序
* 在程序执行是，为了提高性能，会对指令进行重排序
* 重排序
    * 编译器的重排序
    * 处理器的指令并行
        * 通过流水线等技术实现多条指令同时并行执行的并行技术
    * 处理器的重排序
        * 由于读写的时候可能发生在缓冲区，可能发生在主内存，所以看起来是在乱序执行
* 现代处理器都会允许写-读指令重排序，但是存在数据依赖的情况不允许重排序

* 写缓冲区
    * 现代处理器，将临时保存的数据写入写缓冲区。这样可以保证指令不切换到主内存进行等待而继续执行
    * 通过批量刷新的方式，减少了内存对总线的占用
    * 坏处:由于写缓冲区只对当前cpu可见，会导致处理器对读写指令的执行顺序与预期不同
    > 会出现对一个数据写入，从代码上看已经完成了，但是实际上只是写的了缓冲区，只有真正刷新到主内存，才算写入过程完成。所以看起来就像在乱序执行读写操作
    
* happens-before原则
    * 一个线程中的每个操作，都先行发生于当前线程的后续其它操作
    * 对一个锁的解锁操作，先行发生与随后对这个锁的加锁//todo不理解啊
    * 对一个volatile的写，先行发生与后续对这个volatile的读//todo不理解啊
    * 如果a 先行发生与b ，b 先行发生与 c ，则 a 先行发生与 c
    > happens-before原则仅仅保证俩个操作的操作结果的可见性，不能理解为执行顺序

* 为了控制重排序，java通过插入内存屏障，来解决问题
* 内存屏障的作用
    * java编译器会禁止特定类型编译器重排序
    * 通过编译器在指令中插入内存屏障控制处理器的重排序
* 内存屏障
    * loadload:load1;loadload;load2-->load1的指令优先于load2及后续指令的执行
    * storestore:store1:storestore:store2-->store1的指令刷新到内存，store2才能执行
    * loadstore:load1:loadstore:store2-->load1优先与store2的执行
    * storeload:store1:storeload:load2-->store1操作完成后，才能load2
    
## 对重排序有影响的场景
* 存在数据依赖性的场景
    * a=1;b=a;
        * 先对a进行赋值操作，然后读取a的值
    * a=1;a=2;
        * 连续对a进行赋值操作
    * b=a;a=1;
        * 先读取a的值，然后修改a的值
    * 以上三种叫存在数据依赖性的场景，不会对指令进行重排序。但是多线程的时候，还是会有乱序的情况
* as-if-serial
    * 不管怎么重排序，不能改变单线程执行的结果
    * a=1；b=2；c=a*b；
        * 第一步和第二步是可以重排序的
* 对控制语句的重排序
    ```java
        if(flag){
        int i = 3 + 3;
      }
    ```
    * 在上述例子中，判断语句的执行和求和语句的执行有可能会被重排序，但是单线程下执行时，如果先执行求和，会将int i的值写入一个叫重排序缓冲的硬件缓存中，如果flag为flase就丢弃，如果为true，就使用缓存
    * 上述例子，在多线程执行的时候，会出现问题。

## 顺序一致性内存模型
* 是一个理论模型概念
* 单个线程中的所有操作的顺序与代码的书写顺序一致
* 认为所有的操作都是原子操作，且操作结果对所有线程可见
* 处理器的内存模型和编程语言的内存模型是参考该模型设计的
* 数据竞争
    * 当多个线程没有做合理的同步控制时，会出现数据竞争
    * ex:一个线程写变量a，一个线程读变量a，如果不做合适的同步操作，就会出现数据竞争
    
## JMM内存模型
* 通过监视器锁达到与顺序一致性内存模型的效果
    * 通过对一部分操作进行锁控制，保证互斥执行，释放锁的时候，把本地缓冲区清空，保证对别的线程可见
* JMM不保证代码的执行顺序与代码的书写顺序一致
    * 通过重排序提高指令执行效率
* JMM不保证多个线程看到的执行顺序是一致的
    * 由于处理器写缓冲区的存在
* JMM不保证对64位的long和double变量的写操作具有原子性
    * 从JSR-133(JDK5)开始，只允许对64位的写操作，拆分为俩个32位的写事务，读操作必须是原子的

# java内存模型总结
* 顺序一致性模型只是一个理论的参考模型，不采用的原因是无法高效的利用资源，很多优化受限
* 处理器的内存模型(分析前提是不包括存在数据依赖的读写操作)
    * 放松程序中的写-读操作的顺序，Total Store Ordering，sparc-TSP & X86
    * 放松程序中的写-写操作的顺序，Partial Store Ordering，sparc-PSO
    * 放松程序中的读-写/读-读操作的顺序，Relaxed Memory Order/PowerPC，ia64 & PowerPC
* 几乎所有的现代处理器都使用了写缓冲区技术，所以都是允许写-读重排序的。
* 处理器越是追求性能，则其内存模型就会设计的越弱。
* java编译器在生成字节码的时候，会在特定的位置插入内存屏障来限制处理器的指令重排序，这个屏障是面向JMM的
* JMM在不同的处理器上执行的时候，插入内存屏障的指令和数量也是不相同的，这个屏障是面向处理器的
* JMM屏蔽了不同处理器模型的差异，它在不同的处理器平台之上提供了一个一致的内存模型给程序员

    